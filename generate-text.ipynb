{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ],
   "id": "bfbb858945de745f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Retrieve the data\n",
    "frank_url = 'https://storage.googleapis.com/acg-datasets/tiny_frankenstein.tgz'\n",
    "cache_dir = '.'\n",
    "cache_subdir = \"data\"\n",
    "tf.keras.utils.get_file('tiny_frankenstein.tgz', frank_url, cache_dir=cache_dir, cache_subdir=cache_subdir, extract=True)\n"
   ],
   "id": "6c8cabcf855f3ff1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "\n",
    "frank_file = os.path.join(cache_dir, cache_subdir, 'tiny_frankenstein.txt')\n",
    "with open(frank_file, 'r') as f:\n",
    "    frank_data = f.read().lower()"
   ],
   "id": "248bf6d310005331",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train a model to generate text\n",
    "\n",
    "# Tokenize the data\n",
    "tokenizer = Tokenizer()\n",
    "# corpus = frank_data.split('\\n')\n",
    "# tokenizer.fit_on_texts(corpus)\n",
    "tokenizer.fit_on_texts([frank_data])\n",
    "known_words = len(tokenizer.word_index) \n",
    "total_tokens = known_words + 1 # Add 1 for the padding token\n",
    "\n",
    "\n"
   ],
   "id": "869dd14fc4586acb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert text to tokens\n",
    "# frank_tokens = tokenizer.texts_to_sequences(corpus)[0]\n",
    "frank_tokens = tokenizer.texts_to_sequences([frank_data])[0]"
   ],
   "id": "474e89b38cc6de0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create input sequences\n",
    "def wrangle_data(sequence, sequence_length, batch_size):\n",
    "    sequence_length = sequence_length +1\n",
    "    sequence_expand = tf.expand_dims(sequence, -1)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(sequence_expand)\n",
    "    dataset = dataset.window(sequence_length, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(sequence_length))\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ],
   "id": "336863818236e6ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sequence_length = 72 # more context, but slower training\n",
    "train_data = wrangle_data(frank_tokens, sequence_length, 64)"
   ],
   "id": "7425ec5550790fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the model\n",
    "\n",
    "def bidirectional_rnn_model(total_tokens, sequence_length):\n",
    "    new_model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(total_tokens, 32, input_length=sequence_length),\n",
    "        # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
    "        # tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(total_tokens, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    new_model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(0.03), metrics=['accuracy'])\n",
    "    return new_model"
   ],
   "id": "f24d47db0719493b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "model = bidirectional_rnn_model(total_tokens, sequence_length)\n",
    "model.summary()"
   ],
   "id": "3c1150813c149f85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_data",
   "id": "45bdda0adf0dee72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "history = model.fit(train_data, epochs=10)\n",
   "id": "4f74e40ef9a2b196",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from history import save_history\n",
    "# Save the model\n",
    "model_name = 'frankenstein_bidirectional_rnn'\n",
    "accuracy = model.evaluate(train_data)[1]\n",
    "\n",
    "save_name = f'models/reviews-{model_name}-{len(history.epoch)}-{accuracy:.4f}'\n",
    "model.save(f\"{save_name}.tf\", save_format=\"tf\")\n",
    "save_history(history, save_name)"
   ],
   "id": "c540d1b03478a216",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate text\n",
    "token_lookup = {v:k for k, v in tokenizer.word_index.items()}\n",
    "\n",
    "seed = frank_tokens[-sequence_length:]\n",
    "seed_text = \"\"\n",
    "\n",
    "for t in seed:\n",
    "    seed_text += token_lookup[t] + \" \"\n",
    "    \n",
    "print(seed_text)"
   ],
   "id": "eb653392e2e6a967",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "generate_tokens_length = 50\n",
    "\n",
    "output = []\n",
    "\n",
    "for _ in range(generate_tokens_length):\n",
    "    tokens = pad_sequences([seed], maxlen=sequence_length, padding='pre', truncating='pre')\n",
    "    predicted = model.predict(tokens)\n",
    "    next_token = np.argmax(predicted)\n",
    "    output.append(token_lookup[next_token+1])\n",
    "    seed.append(next_token)\n",
    "    \n",
    "print(' '.join(output))"
   ],
   "id": "9285b32fc32cb47a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ff3b793d66a5ea25",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
